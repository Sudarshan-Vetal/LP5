import numpy as np
import pandas as pd

import tensorflow as tf

import matplotlib.pyplot as plt
%matplotlib inline

from tensorflow.keras.datasets import imdb

from tensorflow.keras.preprocessing.sequence import pad_sequences

num_words=10000
max_len = 300

(X_train, y_train),(X_test, y_test) = imdb.load_data(num_words=num_words)

X_train = pad_sequences(X_train, maxlen=max_len)

X_test = pad_sequences(X_test, maxlen = max_len)

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=num_words, output_dim=32, input_length=max_len),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(
    loss = 'binary_crossentropy',
    optimizer = 'adam',
    metrics=['accuracy']
)

history = model.fit(
    X_train, y_train,
    epochs=10,
    batch_size=32,
    validation_split=0.2
)

loss , acc = model.evaluate(X_test,y_test)

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.legend(loc='lower right')
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.ylim([0,1])
plt.show()

plt.plot(history.history['loss'],label='Loss')
plt.plot(history.history['val_loss'],label='val_loss')
plt.title("Loss Graph")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend('upper left')
plt.ylim([0,1])
plt.show()

def classify_review(review_text):
  word_index = imdb.get_word_index()
  words = review_text.split()
  filtered_words = []
  for word in words:
    if word in word_index and word_index[word]+3 <num_words:
      filtered_words.append(word_index[word]+3)
  words = filtered_words

  words = pad_sequences([words], maxlen=max_len)

  prediction = model.predict(words)
  if prediction>=0.5:
    return "Positive"
  else:
    return "Negative"

review1 = 'This movie was amazing! I loved every moment of it.'
print(classify_review(review1))

review2 = 'The movie was very boring and tiring.'